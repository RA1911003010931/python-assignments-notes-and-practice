{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   27 84000]\n",
      "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
      "0  15624510    Male   19            19000          0\n",
      "1  15810944    Male   35            20000          0\n",
      "2  15668575  Female   26            43000          0\n",
      "3  15603246  Female   27            57000          0\n",
      "4  15804002    Male   19            76000          0\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[55  3]\n",
      " [ 4 18]]\n",
      "0.9125\n"
     ]
    }
   ],
   "source": [
    "#classification using naive bayes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "#print(X[6])\n",
    "print(dataset.head())\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Training the Naive Bayes model on the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "ac = accuracy_score(y_test,y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"confusion matrix\")\n",
    "print(cm)\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 words in our dictionary are: \n",
      "['a', 'ability', 'able', 'about', 'above', 'accept', 'according', 'account', 'across', 'act']\n",
      "The dictionary has 1001 words \n",
      "The dictionary has  1001 key values pairs\n",
      "Enter any word: bok\n",
      "word 0: boy, probability 0.000999\n",
      "word 1: ok, probability 0.000999\n",
      "word 2: box, probability 0.000999\n",
      "word 3: book, probability 0.000999\n"
     ]
    }
   ],
   "source": [
    "#correct word prediction\n",
    "import re \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "w = []\n",
    "with open('sample.txt','r',encoding=\"utf8\") as f:\n",
    "    file_name_data = f.read()\n",
    "    file_name_data = file_name_data.lower()\n",
    "    w = re.findall('\\w+', file_name_data)\n",
    "\n",
    "v = set(w)\n",
    "print(f\"The first 10 words in our dictionary are: \\n{w[0:10]}\")\n",
    "print(f\"The dictionary has {len(v)} words \")\n",
    "\n",
    "def get_count(words):\n",
    "    word_count = {}\n",
    "    for word in words:\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "    return word_count\n",
    "\n",
    "word_count = get_count(w)\n",
    "print(f\"The dictionary has  {len(word_count)} key values pairs\")\n",
    "\n",
    "def get_probs(word_count_dict):\n",
    "    probs = {}\n",
    "    m = sum(word_count_dict.values())\n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key] = word_count_dict[key] / m\n",
    "    return probs\n",
    "\n",
    "def DeleteLetter(word):\n",
    "    delete_list = []\n",
    "    split_list = []\n",
    "    for i in range(len(word)):\n",
    "        split_list.append((word[0:i], word[i:]))\n",
    "    for a, b in split_list:\n",
    "        delete_list.append(a + b[1:])\n",
    "    return delete_list\n",
    "\n",
    "delete_word_l = DeleteLetter(word=\"cans\")\n",
    "\n",
    "\n",
    "def SwitchLetter(word):\n",
    "    split_l = []\n",
    "    switch_l = []\n",
    "    for i in range(len(word)):\n",
    "        split_l.append((word[0:i], word[i:]))\n",
    "    switch_l = [a + b[1] + b[0] + b[2:] for a, b in split_l if len(b) >= 2]\n",
    "    return switch_l\n",
    "\n",
    "switch_word_l = SwitchLetter(word=\"eta\")\n",
    "\n",
    "def replace_letter(word):\n",
    "    split_l = []\n",
    "    replace_list = []\n",
    "    for i in range(len(word)):\n",
    "        split_l.append((word[0:i], word[i:]))\n",
    "    alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_list = [a + l + (b[1:] if len(b) > 1 else '') for a, b in split_l if b for l in alphabets]\n",
    "    return replace_list\n",
    "\n",
    "replace_l = replace_letter(word='can')\n",
    "\n",
    "def insert_letter(word):\n",
    "    split_l = []\n",
    "    insert_list = []\n",
    "    for i in range(len(word) + 1):\n",
    "        split_l.append((word[0:i], word[i:]))\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_list = [a + l + b for a, b in split_l for l in letters]\n",
    "    return insert_list\n",
    "\n",
    "def edit_one_letter(word, allow_switches=True):\n",
    "    edit_set1 = set()\n",
    "    edit_set1.update(DeleteLetter(word))\n",
    "    if allow_switches:\n",
    "        edit_set1.update(SwitchLetter(word))\n",
    "    edit_set1.update(replace_letter(word))\n",
    "    edit_set1.update(insert_letter(word))\n",
    "    return edit_set1\n",
    "\n",
    "def edit_two_letters(word, allow_switches=True):\n",
    "    edit_set2 = set()\n",
    "    edit_one = edit_one_letter(word, allow_switches=allow_switches)\n",
    "    for w in edit_one:\n",
    "        if w:\n",
    "            edit_two = edit_one_letter(w, allow_switches=allow_switches)\n",
    "            edit_set2.update(edit_two)\n",
    "    return edit_set2\n",
    "\n",
    "def get_corrections(word, probs, vocab, n=2):\n",
    "    suggested_word = []\n",
    "    best_suggestion = []\n",
    "    suggested_word = list(\n",
    "        (word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(\n",
    "            vocab))\n",
    "    best_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
    "    return best_suggestion\n",
    "\n",
    "\n",
    "my_word = input(\"Enter any word: \")\n",
    "probs = get_probs(word_count)\n",
    "if my_word in v:\n",
    "        print('Your word seems to be correct')\n",
    "else:\n",
    "    tmp_corrections = get_corrections(my_word, probs, v, 2)\n",
    "    for i, word_prob in enumerate(tmp_corrections):\n",
    "        print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
